---
title: "COVID-19"
author: "Team Delta"
date: 2021-10-20
output:
  github_document:
    toc: true
---

# Project 1

## Team Check-In October 14

1.  What's your question?

    -   Is there a correlation between temperature and COVID cases?

2.  What data do you plan to use to answer this question?

    -   Hopefully NOAA R weather library data

3.  What challenges do you anticipate encountering?

    -   Difficulty with getting data to work for our purposes

    -   The weather dataset is extremely large, so operations may take significant time to run if we don't design code to account for this

    -   Determining if any trends we see are actually significant or due to coincidence or other variables (eg. cold weather around holidays)

4.  What level of complexity of the final product are you aiming for?

    -   Closer to MVP due to other commitments

5.  What figures / tables do you anticipate producing?

    -   A line plot of weather and COVID cases over time for a specific location on the same axis, maybe faceted or color-coded by different regions

    -   Scatter plot of weather comfortable-ness vs COVID cases 2 weeks later (possibly for a specific time)

    -   We don't have any specific table ideas yet

<!-- -------------------------------------------------- -->

```{r setup}
library(tidyverse)
```

# Data

<!-- -------------------------------------------------- -->

We used several different sources of data for this project.

1.  County-level population estimates ([Census Bureau](data.census.gov))
2.  County-level COVID-19 counts (New York Times)
3.  Weather data

### **Load Census Data.** Make sure the column names are `id, Geographic Area Name, Estimate!!Total, Margin of Error!!Total`.

See the README.md file for instructions to download this data from the Census Bureau website.

```{r census-data}
filename <- "./data/census.csv"

## Load the data
df_pop <- 
  read_csv(filename, skip = 1) %>% 
  mutate("fips" = str_remove(id, "\\d+[:alpha:]+"))
# df_pop %>% knitr::kable()
```

### Automated Download of NYT Data

The New York Times is publishing up-to-date data on COVID-19 on [GitHub](https://github.com/nytimes/covid-19-data).

```{r covid-data}
url_counties <- "https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"

filename_nyt <- "./data/nyt_counties.csv"

## Download the data locally
curl::curl_download(
        url_counties,
        destfile = filename_nyt
      )

## Loads the downloaded csv
df_covid <- read_csv(filename_nyt)
```
```{r glimpse}
df_pop %>% glimpse
df_covid %>% glimpse
```


```{r combine}
## NOTE: No need to change; run this to produce a more convenient tibble
df_data <-
  df_covid %>%
  left_join(df_pop, by = "fips") %>% 
  select(
    date,
    county,
    state,
    fips,
    cases,
    deaths,
    population = `Estimate!!Total`
  )
glimpse(df_data)
```


#### Normalize

```{r normalize}
## TASK: Normalize cases and deaths
df_normalized <-
  df_data %>%
  group_by(county) %>%
  mutate("cases_per100k" = (cases / population) * 100000) %>%
  mutate("deaths_per100k" = (deaths / population) * 100000) %>%
  ungroup()

glimpse(df_normalized)
```
```{r tidy}
df_tidy <- df_normalized %>% 
  separate(date,
           into = c("year", "month", "day"),
           sep = "-", 
           remove = FALSE) %>% 
  mutate(year = as.integer(year), 
         month = as.integer(month), 
         day = as.integer(day))

df_tidy
```

```{r daily}
df_daily <- df_tidy %>% 
  group_by(fips) %>% 
  mutate(
    daily_case_count = cases_per100k - lag(cases_per100k),
    daily_death_count = deaths_per100k - lag(deaths_per100k)
  )
                                           
```

### Weather Data

Follow instructions linked [here](https://docs.ropensci.org/rnoaa/articles/rnoaa.html)

```{r weather-data-setup}
library('rnoaa')
# Replace with your key from here: https://www.ncdc.noaa.gov/cdo-web/token
# Remember to delete your actual API key before git pushing!
options(noaakey = "mXlBMxxMYipwDjTiNYqCqZSTVjvFyDSH")
```

I have not been able to figure out a way to just set everything equal to a data frame. It seems like you need to make calls for a specific location using the functions.

Once that is figured out, we need to connect the datasets using location and time. I think there should be some way to connect them using the ZIP (each county has 1 FIPS but can have multiple ZIP codes, however, we could probably find a lookup table of FIPS -\> ZIP in order to connect the 2 tables). If not, the location ID also uses the FIPS.

```{r get_weather_data}
get_weather_data <- 
  function(FIPS) {
    out1 <- ncdc(
    datasetid='GHCND', # Daily summaries dataset
    locationid = str_c("FIPS:", FIPS),
    datatypeid='TAVG',
    startdate = '2020-05-01',
    enddate = '2020-12-31' ,
    limit = 1000
    )
    
    out2 <- ncdc(
    datasetid='GHCND', # Daily summaries dataset
    locationid = str_c("FIPS:", FIPS),
    datatypeid='TAVG',
    startdate = '2021-01-01',
    enddate = '2021-10-16',
    limit = 1000
    )
    
  out <- bind_rows(out1$data, out2$data)
  # out <- ncdc_combine(out1, out2)
  out
  }
```


```{r weather-data}
stations <-
  ghcnd_stations(refresh = FALSE) %>%
  filter(last_year == 2021 & str_detect(id, "US")) 
# filter for stations still operating in 2021 and stations in the US
# There are 136,293 stations meeting these criteria
stations
```

## Plot Single County

```{r get_county_data}
get_county_data <- 
  function(county_fips) {
    weather_data <- get_weather_data(county_fips) %>%       mutate(date = as.Date(date)) 
    
    covid_data <- df_daily %>% 
      filter(fips == county_fips)
    
    combined_data <- covid_data %>%
      right_join(weather_data, by = "date") %>% 
      mutate(temp = value/10) %>%
      mutate(temp_from_median = abs(temp - 21)) %>% 
      select(-value)
    
    combined_data
  }
```


```{r plot_county_data}
plot_county_data <- 
  function(combined_data, county_name) {
  titlename <- county_name
  combined_data %>% 
        ggplot(aes(x = date)) +
        
        geom_smooth(mapping = aes(
          y = temp_from_median, 
          color = "Difference in \nTemperature \nfrom 21C"),
          span = .1,
          se = FALSE
        ) +
        
        geom_smooth(mapping = aes(
          y = daily_case_count / 10,
          color = "Daily Cases"),
          span = .01,
          se = FALSE
        ) +
  
        scale_y_continuous(
          name = "Temperature (C)",
          sec.axis = sec_axis(
            trans = ~.*10, 
            name="Cases/day (avg)"
            )
        ) +
        
        theme(
          axis.text.x = element_text(angle = 90),
          legend.title = element_blank()
        ) +
        labs(title = titlename, 
             subtitle = "Correlation Between Covid Cases and Temperature"
        ) +
    
        scale_x_date(date_labels="%b %y",
                     date_breaks  ="3 month")
  }
```

```{r}
data1 <- get_county_data("47157")
data2 <- get_county_data("17031")
data3 <- get_county_data("36001")
data4 <- get_county_data("13121")
data5 <- get_county_data("04013")
data6 <- get_county_data("41051")
data7 <- get_county_data("48113")
data8 <- get_county_data("22071")
```

```{r}
plot_county_data(data1, "Shelby County (TN)")
plot_county_data(data2, "Cook County (IL)")
plot_county_data(data3, "Albany County (NY)")
plot_county_data(data4, "Fulton County (GA)")
plot_county_data(data5, "Maricopa County (AZ)")
plot_county_data(data6, "Multnomah County (OR)")
plot_county_data(data7, "Dallas County (TX)")
plot_county_data(data8, "Orleans Parish (GA)")

```
```{r correlation}

pearson1 <- data1 %>%
  summarize(rho = cor(temp_from_median, daily_case_count, method = "pearson"))
pearson2 <- data2 %>%
  summarize(rho = cor(temp_from_median, daily_case_count, method = "pearson"))
pearson3 <- data3 %>%
  summarize(rho = cor(temp_from_median, daily_case_count, method = "pearson"))
pearson4 <- data4 %>%
  summarize(rho = cor(temp_from_median, daily_case_count, method = "pearson"))
pearson5 <- data5 %>%
  summarize(rho = cor(temp_from_median, daily_case_count, method = "pearson"))
pearson6 <- data6 %>%
  summarize(rho = cor(temp_from_median, daily_case_count, method = "pearson"))
pearson7 <- data7 %>%
  summarize(rho = cor(temp_from_median, daily_case_count, method = "pearson"))
pearson8 <- data8 %>%
  summarize(rho = cor(temp_from_median, daily_case_count, method = "pearson"))

rho_pearson <- data.frame(pearson1, pearson2, pearson3, pearson4, pearson5, pearson6, pearson7, pearson8)
rho_pearson


spearman1 <- data1 %>%
  summarize(rho = cor(temp_from_median, daily_case_count, method = "spearman"))
spearman2 <- data2 %>%
  summarize(rho = cor(temp_from_median, daily_case_count, method = "spearman"))
spearman3 <- data3 %>%
  summarize(rho = cor(temp_from_median, daily_case_count, method = "spearman"))
spearman4 <- data4 %>%
  summarize(rho = cor(temp_from_median, daily_case_count, method = "spearman"))
spearman5 <- data5 %>%
  summarize(rho = cor(temp_from_median, daily_case_count, method = "spearman"))
spearman6 <- data6 %>%
  summarize(rho = cor(temp_from_median, daily_case_count, method = "spearman"))
spearman7 <- data7 %>%
  summarize(rho = cor(temp_from_median, daily_case_count, method = "spearman"))
spearman8 <- data8 %>%
  summarize(rho = cor(temp_from_median, daily_case_count, method = "spearman"))

rho_spearman <- data.frame(spearman1, spearman2, spearman3, spearman4, spearman5, spearman6, spearman7, spearman8)
rho_spearman
```


